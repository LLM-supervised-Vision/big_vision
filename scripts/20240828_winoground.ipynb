{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/vlm-pd/miniconda3/envs/vlm/lib/python3.10/site-packages/IPython/core/magics/osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n",
      "/mnt/vlm-pd/miniconda3/envs/vlm/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/austinwang/austin_big_vision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 17:51:56.681569: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-29 17:51:56.705062: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-29 17:51:56.712310: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-29 17:51:58.088241: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/mnt/vlm-pd/miniconda3/envs/vlm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd ~/austin_big_vision\n",
    "import jax\n",
    "import json\n",
    "import importlib\n",
    "import numpy as np\n",
    "import ml_collections\n",
    "import jax.numpy as jnp\n",
    "import tensorflow as tf\n",
    "\n",
    "from datasets import load_dataset\n",
    "import big_vision.pp.builder as pp_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "backbone = 'gemma2b-half-0.1_b16-F_contrastive'\n",
    "\n",
    "# setup\n",
    "backbone_dict = {\n",
    "    'clip': 'gs://us-central2-storage/tensorflow_datasets/vit-b-16_3b_pretraining/clip_bs16384_warm10k_lr1e-3_wd1e-4_bf16_qknorm-F_b2-0.95_12lyr_07-23_1510',\n",
    "    'clip_map': 'gs://us-central2-storage/tensorflow_datasets/vit-b-16_3b_pretraining/clip_autoregressive_bs16384_warm0.03_lr1e-3_wd1e-4_bf16_qknorm-F_b2-0.95_12lyr_06-24_2019',\n",
    "    'clip_s9b': 'gs://us-central2-storage/tensorflow_datasets/vit-b-16_3b_pretraining/clip_autoregressive_s9b_bs16384_warm0.03_lr1e-3_wd1e-4_bf16_qknorm-F_b2-0.95_12lyr_08-04_0839',\n",
    "    'clip_s9b_bs32k': 'gs://us-central2-storage/tensorflow_datasets/vit-b-16_3b_pretraining/clip_s9b_bs32k_warm0.03_lr1e-3_wd1e-4_bf16_qknorm-F_b2-0.95_08-09_0655',\n",
    "    'siglip': 'gs://us-central2-storage/tensorflow_datasets/vit-b-16_3b_pretraining/siglip_parallel_bs16384_warm0.03_lr1e-3_wd1e-4_bf16_qknorm-F_b2-0.95_12lyr_06-24_2019',\n",
    "    'siglip_v4-32': 'gs://us-central2-storage/tensorflow_datasets/vit-b-16_3b_pretraining/siglip_replication_pod_04-11_2247',\n",
    "    'siglip_s9b_bs32k': 'gs://us-central2-storage/tensorflow_datasets/vit-b-16_3b_pretraining/siglip_s9b_bs32k_warm0.03_lr1e-3_wd1e-4_bf16_qknorm-F_b2-0.95_08-04_0839',\n",
    "    'cappa': 'gs://us-central2-storage/tensorflow_datasets/vit-b-16_3b_pretraining/cappa_bs16384_s3B_warm0.03_lr1e-3_wd1e-4_bf16_qknorm-F_b2-0.95_6lyr_06-27_2108',\n",
    "    # 'cappa_decoder-qknorm-T_warm0.02': 'gs://us-central2-storage/tensorflow_datasets/cappa_bs16384_warm0.02_lr1e-3_wd1e-4_bf16_b2-0.95_6lyr_06-15_2102',\n",
    "    'cappa_s9b': 'gs://us-central2-storage/tensorflow_datasets/cappa_bs16384_s9B_warm0.02_lr1e-3_wd1e-4_bf16_qknorm-F_b2-0.95_6lyr_06-27_2108',\n",
    "    'cappa_s9b_bs32k': 'gs://us-central2-storage/tensorflow_datasets/cappa_bs32768_s9B_warm0.03_lr1e-3_wd1e-4_bf16_qknorm-F_b2-0.95_6lyr_08-07_2217',\n",
    "    'coca_6lyr': 'gs://us-central2-storage/tensorflow_datasets/vit-b-16_3b_pretraining/coca_replication_bs16384_warm0.03_1.0co-2.0ca_lr1e-3_wd1e-4_bf16_qknorm-F_b2-0.95_6lyr_06-30_1841',\n",
    "    'coca_unified': 'gs://us-central2-storage/tensorflow_datasets/vit-b-16_3b_pretraining/coca_replication_s3b_bs16384_warm0.03_1.0co-1.0ca_lr1e-3_wd1e-4_bf16_qknorm-F_b2-0.95_6lyr_scan-F_fsdp-F_08-19_0355',\n",
    "    'coca_1.0co_1.0ca_6lyr_qknorm-T_warm0.02': 'gs://us-central2-storage/tensorflow_datasets/ckpts/coca_replication_bs16384_warm0.02_1.0co-1.0ca_lr1e-3_wd1e-4_bf16_b2-0.95_6lyr_06-10_2225',\n",
    "    'coca': 'gs://us-central2-storage/tensorflow_datasets/vit-b-16_3b_pretraining/coca_replication_bs32768_warm0.03_1.0co-1.0ca_lr1e-3_wd1e-4_bf16_qknorm-F_b2-0.95_6lyr_scan-F_fsdp-F_08-12_2313',\n",
    "    'coca_6lyr_1.0co_1.0ca_s9b_bs32k': 'gs://us-central2-storage/tensorflow_datasets/vit-b-16_3b_pretraining/coca_replication_s9b_bs32768_warm0.03_1.0co-1.0ca_lr1e-3_wd1e-4_bf16_qknorm-F_b2-0.95_6lyr_scan-F_fsdp-F_08-14_1614',\n",
    "    'gemma2b-half-0.1_b16-F_contrastive': 'gs://us-central2-storage/tensorflow_datasets/mllm_ckpts/paligemma/gemma2b-half-0.1_so400m-F_contrastive_bs16384_s3b_wd1e-4_08-21_1935',\n",
    "}\n",
    "backbone_path = backbone_dict[backbone]\n",
    "config_path = f'{backbone_path}/config.json'\n",
    "config = ml_collections.ConfigDict(json.load(tf.io.gfile.GFile(config_path, \"r\")))\n",
    "for m in config.get(\"pp_modules\", [\"ops_general\", \"ops_image\", \"ops_text\"]): importlib.import_module(f\"big_vision.pp.{m}\")\n",
    "\n",
    "# load model\n",
    "print(f\"Loading model\")\n",
    "model_cfg = config.model\n",
    "img_key = 'img' if 'image' in model_cfg or 'img' in model_cfg else 'encoder'\n",
    "model_mod = importlib.import_module(f\"big_vision.models.{config.model_name}\")\n",
    "bv_model = model_mod.Model(**model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from gs://us-central2-storage/tensorflow_datasets/mllm_ckpts/paligemma/gemma2b-half-0.1_so400m-F_contrastive_bs16384_s3b_wd1e-4_08-21_1935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724953974.716876 4128907 gcs_resource.cc:109] Using default AdmissionQueue with limit 32\n",
      "I0000 00:00:1724953974.721349 4130730 google_auth_provider.cc:180] Running on GCE, using service account 373177222751-compute@developer.gserviceaccount.com\n",
      "/tmp/ipykernel_4128907/1054928771.py:15: DeprecationWarning: jax.tree_map is deprecated: use jax.tree.map (jax v0.4.25 or newer) or jax.tree_util.tree_map (any JAX version).\n",
      "  jax.tree_map(jnp.shape, params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'img': {'Transformer': {'encoder_norm': {'bias': (768,), 'scale': (768,)},\n",
       "   'encoderblock': {'LayerNorm_0': {'bias': (12, 768), 'scale': (12, 768)},\n",
       "    'LayerNorm_1': {'bias': (12, 768), 'scale': (12, 768)},\n",
       "    'MlpBlock_0': {'Dense_0': {'bias': (12, 3072), 'kernel': (12, 768, 3072)},\n",
       "     'Dense_1': {'bias': (12, 768), 'kernel': (12, 3072, 768)}},\n",
       "    'MultiHeadDotProductAttention_0': {'key': {'bias': (12, 12, 64),\n",
       "      'kernel': (12, 768, 12, 64)},\n",
       "     'out': {'bias': (12, 768), 'kernel': (12, 12, 64, 768)},\n",
       "     'query': {'bias': (12, 12, 64), 'kernel': (12, 768, 12, 64)},\n",
       "     'value': {'bias': (12, 12, 64), 'kernel': (12, 768, 12, 64)}}}},\n",
       "  'embedding': {'bias': (768,), 'kernel': (16, 16, 3, 768)},\n",
       "  'head': {'bias': (2048,), 'kernel': (768, 2048)},\n",
       "  'pos_embedding': (1, 196, 768)},\n",
       " 'llm': {'embedder': {'input_embedding': (257152, 2048)},\n",
       "  'final_norm': {'scale': (2048,)},\n",
       "  'layers': {'attn': {'attn_vec_einsum': {'w': (9, 8, 256, 2048)},\n",
       "    'kv_einsum': {'w': (9, 2, 1, 2048, 256)},\n",
       "    'q_einsum': {'w': (9, 8, 2048, 256)}},\n",
       "   'mlp': {'gating_einsum': (9, 2, 2048, 16384), 'linear': (9, 16384, 2048)},\n",
       "   'pre_attention_norm': {'scale': (9, 2048)},\n",
       "   'pre_ffw_norm': {'scale': (9, 2048)}}},\n",
       " 't': (1,)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load ckpt weights\n",
    "print(f'Loading weights from {backbone_path}')\n",
    "rng = jax.random.PRNGKey(42)\n",
    "dummy_img = jnp.zeros([2, 224, 224, 3], jnp.float32)\n",
    "dummy_txt = jnp.zeros([2, 64], jnp.int32)\n",
    "dummy_mask_ar = jnp.zeros([2, 64], jnp.bool_) if 'llm' in model_cfg else None\n",
    "if dummy_mask_ar is not None:\n",
    "    init_params = jax.jit(bv_model.init, backend=\"cpu\")(rng, dummy_img, dummy_txt,dummy_mask_ar)['params']\n",
    "else:\n",
    "    init_params = jax.jit(bv_model.init, backend=\"cpu\")(rng, dummy_img, dummy_txt)['params']\n",
    "\n",
    "img_load_kw = {'dont_load': ('.*_ln/scale','head/kernel', 'head/bias')}\n",
    "ckpt_path = f'{backbone_path}/checkpoint.bv-{config.total_steps:09d}'\n",
    "params = model_mod.load(init_params, ckpt_path, model_cfg, img_load_kw)\n",
    "jax.tree_map(jnp.shape, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winoground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = load_dataset('facebook/winoground', token=\"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\",trust_remote_code=True)['test']\n",
    "pp_img_idx = config.input.pp.split('|').index('value_range(-1,1)')\n",
    "pp_img = pp_builder.get_preprocess_fn('|'.join(config.input.pp.split('|')[1:pp_img_idx+1]))\n",
    "pp_txt = pp_builder.get_preprocess_fn('|'.join(config.input.pp.split('|')[pp_img_idx+1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing images\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(400, 224, 224, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Preprocessing images\")\n",
    "i0 = jnp.array([pp_img({\"image\": jnp.asarray(img.convert('RGB'))})['image'] for img in examples['image_0']])\n",
    "i1 = jnp.array([pp_img({\"image\": jnp.asarray(img.convert('RGB'))})['image'] for img in examples['image_1']])\n",
    "i0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing text\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mask_ar': (400, 65), 'mask_loss': (400, 65), 'text': (400, 65)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Preprocessing text\")\n",
    "c0_list, c0_dict = [pp_txt({\"caption\": txt}) for txt in examples['caption_0']], {}\n",
    "for k in c0_list[0].keys(): c0_dict[k] = jnp.array([d[k] for d in c0_list])\n",
    "c1_list, c1_dict = [pp_txt({\"caption\": txt}) for txt in examples['caption_1']], {}\n",
    "for k in c1_list[0].keys(): c1_dict[k] = jnp.array([d[k] for d in c1_list])\n",
    "jax.tree.map(lambda x: x.shape, c0_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing image embeddings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(400, 196, 2048)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Computing image embeddings\")\n",
    "zimg_0, _ = bv_model.apply({\"params\":params}, i0, method='embed_image')\n",
    "zimg_1, _ = bv_model.apply({\"params\":params}, i1, method='embed_image')\n",
    "zimg_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing text embeddings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(400, 64, 2048)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Computing text embeddings\")\n",
    "ztxt_0 = bv_model.apply(\n",
    "    {\"params\":params}, \n",
    "    None, c0_dict['text'][:,:-1], \n",
    "    c0_dict['mask_ar'][:,:-1], \n",
    "    is_blind=True\n",
    ")[1]['llm/pre_logits']\n",
    "ztxt_1 = bv_model.apply(\n",
    "    {\"params\":params}, \n",
    "    None, c1_dict['text'][:,:-1],\n",
    "    c1_dict['mask_ar'][:,:-1],\n",
    "    is_blind=True\n",
    ")[1]['llm/pre_logits']\n",
    "ztxt_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing similarities\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Computing similarities\")\n",
    "def mean_normalize(x): \n",
    "    x = x.mean(1)\n",
    "    return x / jnp.linalg.norm(x, axis=-1, keepdims=True)\n",
    "zi0, zi1, zc0, zc1 = map(mean_normalize, [zimg_0, zimg_1, ztxt_0, ztxt_1])\n",
    "\n",
    "i0_c0 = jnp.sum(zi0 * zc0, axis=-1)\n",
    "i0_c1 = jnp.sum(zi0 * zc1, axis=-1)\n",
    "i1_c0 = jnp.sum(zi1 * zc0, axis=-1)\n",
    "i1_c1 = jnp.sum(zi1 * zc1, axis=-1)\n",
    "i0_c0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Winoground scores\n",
      "Text Score: 16.25%\n",
      "Image Score: 6.25%\n",
      "Both Score: 2.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing Winoground scores\")\n",
    "# text scores: 1 if i0_c0 > i0_c1 and i1_c1 > i1_c0, 0 otherwise\n",
    "# image scores: 1 if i0_c0 > i1_c0 and i1_c1 > i0_c1, 0 otherwise\n",
    "text_scores = (i0_c0 > i0_c1) & (i1_c1 > i1_c0)\n",
    "image_scores = (i0_c0 > i1_c0) & (i1_c1 > i0_c1)\n",
    "both_scores = text_scores & image_scores\n",
    "def get_acc(scores): \n",
    "    # return eg.72.50%\n",
    "    s = scores.mean().item()*100\n",
    "    return f'{s:.2f}%'\n",
    "print(\"Text Score:\", get_acc(text_scores))\n",
    "print(\"Image Score:\", get_acc(image_scores))\n",
    "print(\"Both Score:\", get_acc(both_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

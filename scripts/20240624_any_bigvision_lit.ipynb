{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/vlm-pd/miniconda3/envs/vlm/lib/python3.11/site-packages/IPython/core/magics/osm.py:393: UserWarning: using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n",
      "/mnt/vlm-pd/miniconda3/envs/vlm/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/austinwang/austin_big_vision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 06:09:01.774839: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%cd ~/austin_big_vision\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import ml_collections\n",
    "import big_vision.models.vit as model_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = ml_collections.ConfigDict()\n",
    "model_cfg.num_classes = None\n",
    "model_cfg.patch_size = (16, 16)\n",
    "model_cfg.width = 768\n",
    "model_cfg.depth = 12\n",
    "model_cfg.mlp_dim = None  # Defaults to 4x input dim\n",
    "model_cfg.num_heads = 12\n",
    "model_cfg.posemb = \"learn\"  # Can also be \"sincos2d\"\n",
    "model_cfg.rep_size = False\n",
    "model_cfg.dropout = 0.0\n",
    "model_cfg.pool_type = \"map\"  # Can also be \"map\" or \"tok\"\n",
    "model_cfg.head_zeroinit = True\n",
    "model_cfg.mask = None\n",
    "model_cfg.normalize_qk = False\n",
    "model_cfg.scan = True\n",
    "model_cfg.remat_policy = \"nothing_saveable\"\n",
    "model_cfg.dtype_mm = \"bfloat16\"\n",
    "\n",
    "model = model_mod.Model(**model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIANT, RES = 'B/16', 224\n",
    "CKPT = 'gs://us-central2-storage/tensorflow_datasets/cappa_bs16384_warm0.02_lr1e-3_wd1e-4_bf16_b2-0.95_6lyr_06-15_2102'\n",
    "TXTVARIANT, EMBDIM, SEQLEN, VOCAB = 'B', 768, 64, 32_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m init_shapes, init_types \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m1\u001b[39m, RES, RES, \u001b[38;5;241m3\u001b[39m), (\u001b[38;5;241m1\u001b[39m, SEQLEN,)],[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbfloat16\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m init_params \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      3\u001b[0m     jnp\u001b[38;5;241m.\u001b[39mzeros(shape, dtype)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m shape, dtype \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(init_shapes, init_types)\n\u001b[1;32m      5\u001b[0m ]\n\u001b[0;32m----> 6\u001b[0m params \u001b[38;5;241m=\u001b[39m model_mod\u001b[38;5;241m.\u001b[39mload(init_params, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCKPT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:img\u001b[39m\u001b[38;5;124m'\u001b[39m, model_cfg)\n",
      "File \u001b[0;32m~/austin_big_vision/big_vision/models/vit.py:431\u001b[0m, in \u001b[0;36mload\u001b[0;34m(init_params, init_file, model_cfg, dont_load)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load init from checkpoint, both old model and this one. +Hi-res posemb.\"\"\"\u001b[39;00m\n\u001b[1;32m    430\u001b[0m init_file \u001b[38;5;241m=\u001b[39m VANITY_NAMES\u001b[38;5;241m.\u001b[39mget(init_file, init_file)\n\u001b[0;32m--> 431\u001b[0m restored_params \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mload_params(init_file)\n\u001b[1;32m    433\u001b[0m restored_params \u001b[38;5;241m=\u001b[39m fix_old_checkpoints(restored_params)\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# Detect attempts to load non-scan checkpoint into scan model.\u001b[39;00m\n",
      "File \u001b[0;32m~/austin_big_vision/big_vision/utils.py:218\u001b[0m, in \u001b[0;36mload_params\u001b[0;34m(ckpt, **kw)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# Here we're now loading new-style tensorstore checkpoints.\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# We can be a more efficient and load params and `key` only right away.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     regex \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m($|/.*)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams/.*\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 218\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m load_checkpoint_ts(ckpt, regex\u001b[38;5;241m=\u001b[39mregex)\n\u001b[1;32m    219\u001b[0m     params \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/austin_big_vision/big_vision/utils.py:918\u001b[0m, in \u001b[0;36mload_checkpoint_ts\u001b[0;34m(path, **tsload_kw)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# Differs based on backend, so blanket catch. pylint:disable=broad-exception-caught\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 918\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tsload(to_load, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtsload_kw)\n",
      "File \u001b[0;32m~/austin_big_vision/big_vision/utils.py:959\u001b[0m, in \u001b[0;36mtsload\u001b[0;34m(path, tree, shardings, regex)\u001b[0m\n\u001b[1;32m    956\u001b[0m   path_names \u001b[38;5;241m=\u001b[39m [p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m path_names \u001b[38;5;28;01mif\u001b[39;00m regex\u001b[38;5;241m.\u001b[39mmatch(p)]\n\u001b[1;32m    957\u001b[0m   tree \u001b[38;5;241m=\u001b[39m recover_tree(path_names, [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(path_names))\n\u001b[0;32m--> 959\u001b[0m names_and_vals, tree_def \u001b[38;5;241m=\u001b[39m tree_flatten_with_names(tree)\n\u001b[1;32m    960\u001b[0m names_to_load, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mnames_and_vals)\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shardings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/austin_big_vision/big_vision/utils.py:635\u001b[0m, in \u001b[0;36mtree_flatten_with_names\u001b[0;34m(tree)\u001b[0m\n\u001b[1;32m    633\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(vals))\n\u001b[1;32m    634\u001b[0m token_tree \u001b[38;5;241m=\u001b[39m tree_def\u001b[38;5;241m.\u001b[39munflatten(tokens)\n\u001b[0;32m--> 635\u001b[0m val_names, perm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m_traverse_with_names(token_tree))\n\u001b[1;32m    636\u001b[0m inv_perm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(perm)\n\u001b[1;32m    638\u001b[0m \u001b[38;5;66;03m# Custom traverasal should visit the same number of leaves.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "init_shapes, init_types = [(1, RES, RES, 3), (1, SEQLEN,)],['bfloat16', 'int32']\n",
    "init_params = [\n",
    "    jnp.zeros(shape, dtype)\n",
    "    for shape, dtype in zip(init_shapes, init_types)\n",
    "]\n",
    "params = model_mod.load(init_params, f'{CKPT}:img', model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

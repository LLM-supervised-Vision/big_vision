{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading DINOv2 ckpts: Timm and FLAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "timm_model = timm.create_model(\"hf_hub:timm/vit_base_patch14_reg4_dinov2.lvd142m\", pretrained=True)\n",
    "timm_model.named_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embeddings': {'cls_token': ShapeDtypeStruct(shape=(1, 1, 768), dtype=float32),\n",
       "  'mask_token': ShapeDtypeStruct(shape=(1, 768), dtype=float32),\n",
       "  'patch_embeddings': {'projection': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "    'kernel': ShapeDtypeStruct(shape=(14, 14, 3, 768), dtype=float32)}},\n",
       "  'position_embeddings': ShapeDtypeStruct(shape=(1, 1370, 768), dtype=float32)},\n",
       " 'encoder': {'layer': {'0': {'attention': {'attention': {'key': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)},\n",
       "      'query': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)},\n",
       "      'value': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)}},\n",
       "     'output': {'dense': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)}}},\n",
       "    'layer_scale1': {'lambda1': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'layer_scale2': {'lambda1': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'mlp': {'fc1': {'bias': ShapeDtypeStruct(shape=(3072,), dtype=float32),\n",
       "      'kernel': ShapeDtypeStruct(shape=(768, 3072), dtype=float32)},\n",
       "     'fc2': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "      'kernel': ShapeDtypeStruct(shape=(3072, 768), dtype=float32)}},\n",
       "    'norm1': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "     'scale': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'norm2': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "     'scale': ShapeDtypeStruct(shape=(768,), dtype=float32)}},\n",
       "   '1': {'attention': {'attention': {'key': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)},\n",
       "      'query': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)},\n",
       "      'value': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)}},\n",
       "     'output': {'dense': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)}}},\n",
       "    'layer_scale1': {'lambda1': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'layer_scale2': {'lambda1': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'mlp': {'fc1': {'bias': ShapeDtypeStruct(shape=(3072,), dtype=float32),\n",
       "      'kernel': ShapeDtypeStruct(shape=(768, 3072), dtype=float32)},\n",
       "     'fc2': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "      'kernel': ShapeDtypeStruct(shape=(3072, 768), dtype=float32)}},\n",
       "    'norm1': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "     'scale': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'norm2': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "     'scale': ShapeDtypeStruct(shape=(768,), dtype=float32)}},\n",
       "   '10': {'attention': {'attention': {'key': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)},\n",
       "      'query': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)},\n",
       "      'value': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)}},\n",
       "     'output': {'dense': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)}}},\n",
       "    'layer_scale1': {'lambda1': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'layer_scale2': {'lambda1': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'mlp': {'fc1': {'bias': ShapeDtypeStruct(shape=(3072,), dtype=float32),\n",
       "      'kernel': ShapeDtypeStruct(shape=(768, 3072), dtype=float32)},\n",
       "     'fc2': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "      'kernel': ShapeDtypeStruct(shape=(3072, 768), dtype=float32)}},\n",
       "    'norm1': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "     'scale': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'norm2': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "     'scale': ShapeDtypeStruct(shape=(768,), dtype=float32)}},\n",
       "   '11': {'attention': {'attention': {'key': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)},\n",
       "      'query': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)},\n",
       "      'value': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)}},\n",
       "     'output': {'dense': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)}}},\n",
       "    'layer_scale1': {'lambda1': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'layer_scale2': {'lambda1': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'mlp': {'fc1': {'bias': ShapeDtypeStruct(shape=(3072,), dtype=float32),\n",
       "      'kernel': ShapeDtypeStruct(shape=(768, 3072), dtype=float32)},\n",
       "     'fc2': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "      'kernel': ShapeDtypeStruct(shape=(3072, 768), dtype=float32)}},\n",
       "    'norm1': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "     'scale': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'norm2': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "     'scale': ShapeDtypeStruct(shape=(768,), dtype=float32)}},\n",
       "   '2': {'attention': {'attention': {'key': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)},\n",
       "      'query': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)},\n",
       "      'value': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)}},\n",
       "     'output': {'dense': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)}}},\n",
       "    'layer_scale1': {'lambda1': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'layer_scale2': {'lambda1': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'mlp': {'fc1': {'bias': ShapeDtypeStruct(shape=(3072,), dtype=float32),\n",
       "      'kernel': ShapeDtypeStruct(shape=(768, 3072), dtype=float32)},\n",
       "     'fc2': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "      'kernel': ShapeDtypeStruct(shape=(3072, 768), dtype=float32)}},\n",
       "    'norm1': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "     'scale': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'norm2': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "     'scale': ShapeDtypeStruct(shape=(768,), dtype=float32)}},\n",
       "   '3': {'attention': {'attention': {'key': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)},\n",
       "      'query': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)},\n",
       "      'value': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)}},\n",
       "     'output': {'dense': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)}}},\n",
       "    'layer_scale1': {'lambda1': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'layer_scale2': {'lambda1': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'mlp': {'fc1': {'bias': ShapeDtypeStruct(shape=(3072,), dtype=float32),\n",
       "      'kernel': ShapeDtypeStruct(shape=(768, 3072), dtype=float32)},\n",
       "     'fc2': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "      'kernel': ShapeDtypeStruct(shape=(3072, 768), dtype=float32)}},\n",
       "    'norm1': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "     'scale': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'norm2': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "     'scale': ShapeDtypeStruct(shape=(768,), dtype=float32)}},\n",
       "   '4': {'attention': {'attention': {'key': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)},\n",
       "      'query': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)},\n",
       "      'value': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)}},\n",
       "     'output': {'dense': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)}}},\n",
       "    'layer_scale1': {'lambda1': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'layer_scale2': {'lambda1': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'mlp': {'fc1': {'bias': ShapeDtypeStruct(shape=(3072,), dtype=float32),\n",
       "      'kernel': ShapeDtypeStruct(shape=(768, 3072), dtype=float32)},\n",
       "     'fc2': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "      'kernel': ShapeDtypeStruct(shape=(3072, 768), dtype=float32)}},\n",
       "    'norm1': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "     'scale': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'norm2': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "     'scale': ShapeDtypeStruct(shape=(768,), dtype=float32)}},\n",
       "   '5': {'attention': {'attention': {'key': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)},\n",
       "      'query': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)},\n",
       "      'value': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)}},\n",
       "     'output': {'dense': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)}}},\n",
       "    'layer_scale1': {'lambda1': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'layer_scale2': {'lambda1': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'mlp': {'fc1': {'bias': ShapeDtypeStruct(shape=(3072,), dtype=float32),\n",
       "      'kernel': ShapeDtypeStruct(shape=(768, 3072), dtype=float32)},\n",
       "     'fc2': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "      'kernel': ShapeDtypeStruct(shape=(3072, 768), dtype=float32)}},\n",
       "    'norm1': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "     'scale': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'norm2': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "     'scale': ShapeDtypeStruct(shape=(768,), dtype=float32)}},\n",
       "   '6': {'attention': {'attention': {'key': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)},\n",
       "      'query': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)},\n",
       "      'value': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)}},\n",
       "     'output': {'dense': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)}}},\n",
       "    'layer_scale1': {'lambda1': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'layer_scale2': {'lambda1': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'mlp': {'fc1': {'bias': ShapeDtypeStruct(shape=(3072,), dtype=float32),\n",
       "      'kernel': ShapeDtypeStruct(shape=(768, 3072), dtype=float32)},\n",
       "     'fc2': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "      'kernel': ShapeDtypeStruct(shape=(3072, 768), dtype=float32)}},\n",
       "    'norm1': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "     'scale': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'norm2': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "     'scale': ShapeDtypeStruct(shape=(768,), dtype=float32)}},\n",
       "   '7': {'attention': {'attention': {'key': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)},\n",
       "      'query': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)},\n",
       "      'value': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)}},\n",
       "     'output': {'dense': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)}}},\n",
       "    'layer_scale1': {'lambda1': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'layer_scale2': {'lambda1': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'mlp': {'fc1': {'bias': ShapeDtypeStruct(shape=(3072,), dtype=float32),\n",
       "      'kernel': ShapeDtypeStruct(shape=(768, 3072), dtype=float32)},\n",
       "     'fc2': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "      'kernel': ShapeDtypeStruct(shape=(3072, 768), dtype=float32)}},\n",
       "    'norm1': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "     'scale': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'norm2': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "     'scale': ShapeDtypeStruct(shape=(768,), dtype=float32)}},\n",
       "   '8': {'attention': {'attention': {'key': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)},\n",
       "      'query': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)},\n",
       "      'value': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)}},\n",
       "     'output': {'dense': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)}}},\n",
       "    'layer_scale1': {'lambda1': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'layer_scale2': {'lambda1': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'mlp': {'fc1': {'bias': ShapeDtypeStruct(shape=(3072,), dtype=float32),\n",
       "      'kernel': ShapeDtypeStruct(shape=(768, 3072), dtype=float32)},\n",
       "     'fc2': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "      'kernel': ShapeDtypeStruct(shape=(3072, 768), dtype=float32)}},\n",
       "    'norm1': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "     'scale': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'norm2': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "     'scale': ShapeDtypeStruct(shape=(768,), dtype=float32)}},\n",
       "   '9': {'attention': {'attention': {'key': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)},\n",
       "      'query': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)},\n",
       "      'value': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)}},\n",
       "     'output': {'dense': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "       'kernel': ShapeDtypeStruct(shape=(768, 768), dtype=float32)}}},\n",
       "    'layer_scale1': {'lambda1': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'layer_scale2': {'lambda1': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'mlp': {'fc1': {'bias': ShapeDtypeStruct(shape=(3072,), dtype=float32),\n",
       "      'kernel': ShapeDtypeStruct(shape=(768, 3072), dtype=float32)},\n",
       "     'fc2': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "      'kernel': ShapeDtypeStruct(shape=(3072, 768), dtype=float32)}},\n",
       "    'norm1': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "     'scale': ShapeDtypeStruct(shape=(768,), dtype=float32)},\n",
       "    'norm2': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "     'scale': ShapeDtypeStruct(shape=(768,), dtype=float32)}}}},\n",
       " 'layernorm': {'bias': ShapeDtypeStruct(shape=(768,), dtype=float32),\n",
       "  'scale': ShapeDtypeStruct(shape=(768,), dtype=float32)}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import FlaxDinov2Model\n",
    "flax_model = FlaxDinov2Model.from_pretrained(\"facebook/dinov2-base\")\n",
    "flax_model._params_shape_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert FLAX model to big_vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/vlm-pd/miniconda3/envs/vlm/lib/python3.10/site-packages/IPython/core/magics/osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n",
      "/mnt/vlm-pd/miniconda3/envs/vlm/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/austinwang/austin_big_vision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-10 22:12:33.566236: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-10 22:12:33.588531: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-10 22:12:33.595481: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-10 22:12:34.690801: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Flax checkpoint...\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd ~/austin_big_vision\n",
    "\n",
    "import io\n",
    "import jax\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import big_vision.utils as u\n",
    "from big_vision.models.vit import scan_to_pyloop\n",
    "\n",
    "def inspect(params):\n",
    "    names_and_vals, _ = u.tree_flatten_with_names(params)\n",
    "    for n,v in names_and_vals:\n",
    "        print(n, v.shape, v.dtype)\n",
    "\n",
    "def save_bigvision_checkpoint(params, output_path):\n",
    "    np.savez(output_path, **params)\n",
    "\n",
    "print(\"Loading Flax checkpoint...\")\n",
    "from transformers import FlaxDinov2Model\n",
    "flax_params = FlaxDinov2Model.from_pretrained(\"facebook/dinov2-base\")._params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting parameters...\n",
      "Transformer/encoder_norm/bias (768,) float32\n",
      "Transformer/encoder_norm/scale (768,) float32\n",
      "Transformer/encoderblock_0/LayerNorm_0/bias (768,) float32\n",
      "Transformer/encoderblock_0/LayerNorm_0/scale (768,) float32\n",
      "Transformer/encoderblock_0/LayerNorm_1/bias (768,) float32\n",
      "Transformer/encoderblock_0/LayerNorm_1/scale (768,) float32\n",
      "Transformer/encoderblock_0/MlpBlock_0/Dense_0/bias (3072,) float32\n",
      "Transformer/encoderblock_0/MlpBlock_0/Dense_0/kernel (768, 3072) float32\n",
      "Transformer/encoderblock_0/MlpBlock_0/Dense_1/bias (768,) float32\n",
      "Transformer/encoderblock_0/MlpBlock_0/Dense_1/kernel (3072, 768) float32\n",
      "Transformer/encoderblock_0/MultiHeadDotProductAttention_0/key/bias (12, 64) float32\n",
      "Transformer/encoderblock_0/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_0/MultiHeadDotProductAttention_0/out/bias (768,) float32\n",
      "Transformer/encoderblock_0/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768) float32\n",
      "Transformer/encoderblock_0/MultiHeadDotProductAttention_0/query/bias (12, 64) float32\n",
      "Transformer/encoderblock_0/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_0/MultiHeadDotProductAttention_0/value/bias (12, 64) float32\n",
      "Transformer/encoderblock_0/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_1/LayerNorm_0/bias (768,) float32\n",
      "Transformer/encoderblock_1/LayerNorm_0/scale (768,) float32\n",
      "Transformer/encoderblock_1/LayerNorm_1/bias (768,) float32\n",
      "Transformer/encoderblock_1/LayerNorm_1/scale (768,) float32\n",
      "Transformer/encoderblock_1/MlpBlock_0/Dense_0/bias (3072,) float32\n",
      "Transformer/encoderblock_1/MlpBlock_0/Dense_0/kernel (768, 3072) float32\n",
      "Transformer/encoderblock_1/MlpBlock_0/Dense_1/bias (768,) float32\n",
      "Transformer/encoderblock_1/MlpBlock_0/Dense_1/kernel (3072, 768) float32\n",
      "Transformer/encoderblock_1/MultiHeadDotProductAttention_0/key/bias (12, 64) float32\n",
      "Transformer/encoderblock_1/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_1/MultiHeadDotProductAttention_0/out/bias (768,) float32\n",
      "Transformer/encoderblock_1/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768) float32\n",
      "Transformer/encoderblock_1/MultiHeadDotProductAttention_0/query/bias (12, 64) float32\n",
      "Transformer/encoderblock_1/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_1/MultiHeadDotProductAttention_0/value/bias (12, 64) float32\n",
      "Transformer/encoderblock_1/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_10/LayerNorm_0/bias (768,) float32\n",
      "Transformer/encoderblock_10/LayerNorm_0/scale (768,) float32\n",
      "Transformer/encoderblock_10/LayerNorm_1/bias (768,) float32\n",
      "Transformer/encoderblock_10/LayerNorm_1/scale (768,) float32\n",
      "Transformer/encoderblock_10/MlpBlock_0/Dense_0/bias (3072,) float32\n",
      "Transformer/encoderblock_10/MlpBlock_0/Dense_0/kernel (768, 3072) float32\n",
      "Transformer/encoderblock_10/MlpBlock_0/Dense_1/bias (768,) float32\n",
      "Transformer/encoderblock_10/MlpBlock_0/Dense_1/kernel (3072, 768) float32\n",
      "Transformer/encoderblock_10/MultiHeadDotProductAttention_0/key/bias (12, 64) float32\n",
      "Transformer/encoderblock_10/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_10/MultiHeadDotProductAttention_0/out/bias (768,) float32\n",
      "Transformer/encoderblock_10/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768) float32\n",
      "Transformer/encoderblock_10/MultiHeadDotProductAttention_0/query/bias (12, 64) float32\n",
      "Transformer/encoderblock_10/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_10/MultiHeadDotProductAttention_0/value/bias (12, 64) float32\n",
      "Transformer/encoderblock_10/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_11/LayerNorm_0/bias (768,) float32\n",
      "Transformer/encoderblock_11/LayerNorm_0/scale (768,) float32\n",
      "Transformer/encoderblock_11/LayerNorm_1/bias (768,) float32\n",
      "Transformer/encoderblock_11/LayerNorm_1/scale (768,) float32\n",
      "Transformer/encoderblock_11/MlpBlock_0/Dense_0/bias (3072,) float32\n",
      "Transformer/encoderblock_11/MlpBlock_0/Dense_0/kernel (768, 3072) float32\n",
      "Transformer/encoderblock_11/MlpBlock_0/Dense_1/bias (768,) float32\n",
      "Transformer/encoderblock_11/MlpBlock_0/Dense_1/kernel (3072, 768) float32\n",
      "Transformer/encoderblock_11/MultiHeadDotProductAttention_0/key/bias (12, 64) float32\n",
      "Transformer/encoderblock_11/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_11/MultiHeadDotProductAttention_0/out/bias (768,) float32\n",
      "Transformer/encoderblock_11/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768) float32\n",
      "Transformer/encoderblock_11/MultiHeadDotProductAttention_0/query/bias (12, 64) float32\n",
      "Transformer/encoderblock_11/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_11/MultiHeadDotProductAttention_0/value/bias (12, 64) float32\n",
      "Transformer/encoderblock_11/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_2/LayerNorm_0/bias (768,) float32\n",
      "Transformer/encoderblock_2/LayerNorm_0/scale (768,) float32\n",
      "Transformer/encoderblock_2/LayerNorm_1/bias (768,) float32\n",
      "Transformer/encoderblock_2/LayerNorm_1/scale (768,) float32\n",
      "Transformer/encoderblock_2/MlpBlock_0/Dense_0/bias (3072,) float32\n",
      "Transformer/encoderblock_2/MlpBlock_0/Dense_0/kernel (768, 3072) float32\n",
      "Transformer/encoderblock_2/MlpBlock_0/Dense_1/bias (768,) float32\n",
      "Transformer/encoderblock_2/MlpBlock_0/Dense_1/kernel (3072, 768) float32\n",
      "Transformer/encoderblock_2/MultiHeadDotProductAttention_0/key/bias (12, 64) float32\n",
      "Transformer/encoderblock_2/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_2/MultiHeadDotProductAttention_0/out/bias (768,) float32\n",
      "Transformer/encoderblock_2/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768) float32\n",
      "Transformer/encoderblock_2/MultiHeadDotProductAttention_0/query/bias (12, 64) float32\n",
      "Transformer/encoderblock_2/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_2/MultiHeadDotProductAttention_0/value/bias (12, 64) float32\n",
      "Transformer/encoderblock_2/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_3/LayerNorm_0/bias (768,) float32\n",
      "Transformer/encoderblock_3/LayerNorm_0/scale (768,) float32\n",
      "Transformer/encoderblock_3/LayerNorm_1/bias (768,) float32\n",
      "Transformer/encoderblock_3/LayerNorm_1/scale (768,) float32\n",
      "Transformer/encoderblock_3/MlpBlock_0/Dense_0/bias (3072,) float32\n",
      "Transformer/encoderblock_3/MlpBlock_0/Dense_0/kernel (768, 3072) float32\n",
      "Transformer/encoderblock_3/MlpBlock_0/Dense_1/bias (768,) float32\n",
      "Transformer/encoderblock_3/MlpBlock_0/Dense_1/kernel (3072, 768) float32\n",
      "Transformer/encoderblock_3/MultiHeadDotProductAttention_0/key/bias (12, 64) float32\n",
      "Transformer/encoderblock_3/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_3/MultiHeadDotProductAttention_0/out/bias (768,) float32\n",
      "Transformer/encoderblock_3/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768) float32\n",
      "Transformer/encoderblock_3/MultiHeadDotProductAttention_0/query/bias (12, 64) float32\n",
      "Transformer/encoderblock_3/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_3/MultiHeadDotProductAttention_0/value/bias (12, 64) float32\n",
      "Transformer/encoderblock_3/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_4/LayerNorm_0/bias (768,) float32\n",
      "Transformer/encoderblock_4/LayerNorm_0/scale (768,) float32\n",
      "Transformer/encoderblock_4/LayerNorm_1/bias (768,) float32\n",
      "Transformer/encoderblock_4/LayerNorm_1/scale (768,) float32\n",
      "Transformer/encoderblock_4/MlpBlock_0/Dense_0/bias (3072,) float32\n",
      "Transformer/encoderblock_4/MlpBlock_0/Dense_0/kernel (768, 3072) float32\n",
      "Transformer/encoderblock_4/MlpBlock_0/Dense_1/bias (768,) float32\n",
      "Transformer/encoderblock_4/MlpBlock_0/Dense_1/kernel (3072, 768) float32\n",
      "Transformer/encoderblock_4/MultiHeadDotProductAttention_0/key/bias (12, 64) float32\n",
      "Transformer/encoderblock_4/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_4/MultiHeadDotProductAttention_0/out/bias (768,) float32\n",
      "Transformer/encoderblock_4/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768) float32\n",
      "Transformer/encoderblock_4/MultiHeadDotProductAttention_0/query/bias (12, 64) float32\n",
      "Transformer/encoderblock_4/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_4/MultiHeadDotProductAttention_0/value/bias (12, 64) float32\n",
      "Transformer/encoderblock_4/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_5/LayerNorm_0/bias (768,) float32\n",
      "Transformer/encoderblock_5/LayerNorm_0/scale (768,) float32\n",
      "Transformer/encoderblock_5/LayerNorm_1/bias (768,) float32\n",
      "Transformer/encoderblock_5/LayerNorm_1/scale (768,) float32\n",
      "Transformer/encoderblock_5/MlpBlock_0/Dense_0/bias (3072,) float32\n",
      "Transformer/encoderblock_5/MlpBlock_0/Dense_0/kernel (768, 3072) float32\n",
      "Transformer/encoderblock_5/MlpBlock_0/Dense_1/bias (768,) float32\n",
      "Transformer/encoderblock_5/MlpBlock_0/Dense_1/kernel (3072, 768) float32\n",
      "Transformer/encoderblock_5/MultiHeadDotProductAttention_0/key/bias (12, 64) float32\n",
      "Transformer/encoderblock_5/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_5/MultiHeadDotProductAttention_0/out/bias (768,) float32\n",
      "Transformer/encoderblock_5/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768) float32\n",
      "Transformer/encoderblock_5/MultiHeadDotProductAttention_0/query/bias (12, 64) float32\n",
      "Transformer/encoderblock_5/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_5/MultiHeadDotProductAttention_0/value/bias (12, 64) float32\n",
      "Transformer/encoderblock_5/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_6/LayerNorm_0/bias (768,) float32\n",
      "Transformer/encoderblock_6/LayerNorm_0/scale (768,) float32\n",
      "Transformer/encoderblock_6/LayerNorm_1/bias (768,) float32\n",
      "Transformer/encoderblock_6/LayerNorm_1/scale (768,) float32\n",
      "Transformer/encoderblock_6/MlpBlock_0/Dense_0/bias (3072,) float32\n",
      "Transformer/encoderblock_6/MlpBlock_0/Dense_0/kernel (768, 3072) float32\n",
      "Transformer/encoderblock_6/MlpBlock_0/Dense_1/bias (768,) float32\n",
      "Transformer/encoderblock_6/MlpBlock_0/Dense_1/kernel (3072, 768) float32\n",
      "Transformer/encoderblock_6/MultiHeadDotProductAttention_0/key/bias (12, 64) float32\n",
      "Transformer/encoderblock_6/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_6/MultiHeadDotProductAttention_0/out/bias (768,) float32\n",
      "Transformer/encoderblock_6/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768) float32\n",
      "Transformer/encoderblock_6/MultiHeadDotProductAttention_0/query/bias (12, 64) float32\n",
      "Transformer/encoderblock_6/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_6/MultiHeadDotProductAttention_0/value/bias (12, 64) float32\n",
      "Transformer/encoderblock_6/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_7/LayerNorm_0/bias (768,) float32\n",
      "Transformer/encoderblock_7/LayerNorm_0/scale (768,) float32\n",
      "Transformer/encoderblock_7/LayerNorm_1/bias (768,) float32\n",
      "Transformer/encoderblock_7/LayerNorm_1/scale (768,) float32\n",
      "Transformer/encoderblock_7/MlpBlock_0/Dense_0/bias (3072,) float32\n",
      "Transformer/encoderblock_7/MlpBlock_0/Dense_0/kernel (768, 3072) float32\n",
      "Transformer/encoderblock_7/MlpBlock_0/Dense_1/bias (768,) float32\n",
      "Transformer/encoderblock_7/MlpBlock_0/Dense_1/kernel (3072, 768) float32\n",
      "Transformer/encoderblock_7/MultiHeadDotProductAttention_0/key/bias (12, 64) float32\n",
      "Transformer/encoderblock_7/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_7/MultiHeadDotProductAttention_0/out/bias (768,) float32\n",
      "Transformer/encoderblock_7/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768) float32\n",
      "Transformer/encoderblock_7/MultiHeadDotProductAttention_0/query/bias (12, 64) float32\n",
      "Transformer/encoderblock_7/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_7/MultiHeadDotProductAttention_0/value/bias (12, 64) float32\n",
      "Transformer/encoderblock_7/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_8/LayerNorm_0/bias (768,) float32\n",
      "Transformer/encoderblock_8/LayerNorm_0/scale (768,) float32\n",
      "Transformer/encoderblock_8/LayerNorm_1/bias (768,) float32\n",
      "Transformer/encoderblock_8/LayerNorm_1/scale (768,) float32\n",
      "Transformer/encoderblock_8/MlpBlock_0/Dense_0/bias (3072,) float32\n",
      "Transformer/encoderblock_8/MlpBlock_0/Dense_0/kernel (768, 3072) float32\n",
      "Transformer/encoderblock_8/MlpBlock_0/Dense_1/bias (768,) float32\n",
      "Transformer/encoderblock_8/MlpBlock_0/Dense_1/kernel (3072, 768) float32\n",
      "Transformer/encoderblock_8/MultiHeadDotProductAttention_0/key/bias (12, 64) float32\n",
      "Transformer/encoderblock_8/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_8/MultiHeadDotProductAttention_0/out/bias (768,) float32\n",
      "Transformer/encoderblock_8/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768) float32\n",
      "Transformer/encoderblock_8/MultiHeadDotProductAttention_0/query/bias (12, 64) float32\n",
      "Transformer/encoderblock_8/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_8/MultiHeadDotProductAttention_0/value/bias (12, 64) float32\n",
      "Transformer/encoderblock_8/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_9/LayerNorm_0/bias (768,) float32\n",
      "Transformer/encoderblock_9/LayerNorm_0/scale (768,) float32\n",
      "Transformer/encoderblock_9/LayerNorm_1/bias (768,) float32\n",
      "Transformer/encoderblock_9/LayerNorm_1/scale (768,) float32\n",
      "Transformer/encoderblock_9/MlpBlock_0/Dense_0/bias (3072,) float32\n",
      "Transformer/encoderblock_9/MlpBlock_0/Dense_0/kernel (768, 3072) float32\n",
      "Transformer/encoderblock_9/MlpBlock_0/Dense_1/bias (768,) float32\n",
      "Transformer/encoderblock_9/MlpBlock_0/Dense_1/kernel (3072, 768) float32\n",
      "Transformer/encoderblock_9/MultiHeadDotProductAttention_0/key/bias (12, 64) float32\n",
      "Transformer/encoderblock_9/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_9/MultiHeadDotProductAttention_0/out/bias (768,) float32\n",
      "Transformer/encoderblock_9/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768) float32\n",
      "Transformer/encoderblock_9/MultiHeadDotProductAttention_0/query/bias (12, 64) float32\n",
      "Transformer/encoderblock_9/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64) float32\n",
      "Transformer/encoderblock_9/MultiHeadDotProductAttention_0/value/bias (12, 64) float32\n",
      "Transformer/encoderblock_9/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64) float32\n",
      "embedding/bias (768,) float32\n",
      "embedding/kernel (768, 3, 14, 14) float32\n",
      "pos_embedding (1, 1370, 768) float32\n"
     ]
    }
   ],
   "source": [
    "print(\"Converting parameters...\")\n",
    "bv_params = {}\n",
    "# Embedding layer\n",
    "bv_params['embedding/kernel'] = jnp.transpose(flax_params['embeddings']['patch_embeddings']['projection']['kernel'], (3, 2, 0, 1))\n",
    "bv_params['embedding/bias'] = flax_params['embeddings']['patch_embeddings']['projection']['bias']\n",
    "# Position embedding\n",
    "bv_params['pos_embedding'] = flax_params['embeddings']['position_embeddings']\n",
    "\n",
    "# Transformer blocks\n",
    "for i in range(12):  # Assuming 12 layers\n",
    "    prefix = f'Transformer/encoderblock_{i}/'\n",
    "    flax_prefix = f'encoder/layer/{i}/'\n",
    "    \n",
    "    # Layer Norm\n",
    "    bv_params[prefix + 'LayerNorm_0/scale'] = flax_params['encoder']['layer'][str(i)]['norm1']['scale']\n",
    "    bv_params[prefix + 'LayerNorm_0/bias'] = flax_params['encoder']['layer'][str(i)]['norm1']['bias']\n",
    "    bv_params[prefix + 'LayerNorm_1/scale'] = flax_params['encoder']['layer'][str(i)]['norm2']['scale']\n",
    "    bv_params[prefix + 'LayerNorm_1/bias'] = flax_params['encoder']['layer'][str(i)]['norm2']['bias']\n",
    "    \n",
    "    # Multi-Head Attention\n",
    "    bv_params[prefix + 'MultiHeadDotProductAttention_0/query/kernel'] = flax_params['encoder']['layer'][str(i)]['attention']['attention']['query']['kernel'].reshape(768, 12, 64)\n",
    "    bv_params[prefix + 'MultiHeadDotProductAttention_0/query/bias'] = flax_params['encoder']['layer'][str(i)]['attention']['attention']['query']['bias'].reshape(12, 64)\n",
    "    bv_params[prefix + 'MultiHeadDotProductAttention_0/key/kernel'] = flax_params['encoder']['layer'][str(i)]['attention']['attention']['key']['kernel'].reshape(768, 12, 64)\n",
    "    bv_params[prefix + 'MultiHeadDotProductAttention_0/key/bias'] = flax_params['encoder']['layer'][str(i)]['attention']['attention']['key']['bias'].reshape(12, 64)\n",
    "    bv_params[prefix + 'MultiHeadDotProductAttention_0/value/kernel'] = flax_params['encoder']['layer'][str(i)]['attention']['attention']['value']['kernel'].reshape(768, 12, 64)\n",
    "    bv_params[prefix + 'MultiHeadDotProductAttention_0/value/bias'] = flax_params['encoder']['layer'][str(i)]['attention']['attention']['value']['bias'].reshape(12, 64)\n",
    "    bv_params[prefix + 'MultiHeadDotProductAttention_0/out/kernel'] = flax_params['encoder']['layer'][str(i)]['attention']['output']['dense']['kernel'].reshape(12, 64, 768)\n",
    "    bv_params[prefix + 'MultiHeadDotProductAttention_0/out/bias'] = flax_params['encoder']['layer'][str(i)]['attention']['output']['dense']['bias']\n",
    "    \n",
    "    # MLP\n",
    "    bv_params[prefix + 'MlpBlock_0/Dense_0/kernel'] = flax_params['encoder']['layer'][str(i)]['mlp']['fc1']['kernel']\n",
    "    bv_params[prefix + 'MlpBlock_0/Dense_0/bias'] = flax_params['encoder']['layer'][str(i)]['mlp']['fc1']['bias']\n",
    "    bv_params[prefix + 'MlpBlock_0/Dense_1/kernel'] = flax_params['encoder']['layer'][str(i)]['mlp']['fc2']['kernel']\n",
    "    bv_params[prefix + 'MlpBlock_0/Dense_1/bias'] = flax_params['encoder']['layer'][str(i)]['mlp']['fc2']['bias']\n",
    "\n",
    "# Final Layer Norm\n",
    "bv_params['Transformer/encoder_norm/scale'] = flax_params['layernorm']['scale']\n",
    "bv_params['Transformer/encoder_norm/bias'] = flax_params['layernorm']['bias']\n",
    "\n",
    "inspect(bv_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_np_save_path = '/home/austinwang/bigvision_dinov2.npz'\n",
    "ckpt = {'params': {'img': bv_params}}\n",
    "io_buffer = io.BytesIO()\n",
    "names_and_vals, _ = u.tree_flatten_with_names(ckpt)\n",
    "np.savez(io_buffer, **{k: v for k, v in names_and_vals})\n",
    "\n",
    "with open(local_np_save_path, 'wb') as f: f.write(io_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params/img/Transformer/encoder_norm/bias (768,) float32\n",
      "params/img/Transformer/encoder_norm/scale (768,) float32\n",
      "params/img/Transformer/encoderblock_0/LayerNorm_0/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_0/LayerNorm_0/scale (768,) float32\n",
      "params/img/Transformer/encoderblock_0/LayerNorm_1/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_0/LayerNorm_1/scale (768,) float32\n",
      "params/img/Transformer/encoderblock_0/MlpBlock_0/Dense_0/bias (3072,) float32\n",
      "params/img/Transformer/encoderblock_0/MlpBlock_0/Dense_0/kernel (768, 3072) float32\n",
      "params/img/Transformer/encoderblock_0/MlpBlock_0/Dense_1/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_0/MlpBlock_0/Dense_1/kernel (3072, 768) float32\n",
      "params/img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/key/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/out/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768) float32\n",
      "params/img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/query/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/value/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_1/LayerNorm_0/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_1/LayerNorm_0/scale (768,) float32\n",
      "params/img/Transformer/encoderblock_1/LayerNorm_1/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_1/LayerNorm_1/scale (768,) float32\n",
      "params/img/Transformer/encoderblock_1/MlpBlock_0/Dense_0/bias (3072,) float32\n",
      "params/img/Transformer/encoderblock_1/MlpBlock_0/Dense_0/kernel (768, 3072) float32\n",
      "params/img/Transformer/encoderblock_1/MlpBlock_0/Dense_1/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_1/MlpBlock_0/Dense_1/kernel (3072, 768) float32\n",
      "params/img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/key/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/out/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768) float32\n",
      "params/img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/query/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/value/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_10/LayerNorm_0/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_10/LayerNorm_0/scale (768,) float32\n",
      "params/img/Transformer/encoderblock_10/LayerNorm_1/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_10/LayerNorm_1/scale (768,) float32\n",
      "params/img/Transformer/encoderblock_10/MlpBlock_0/Dense_0/bias (3072,) float32\n",
      "params/img/Transformer/encoderblock_10/MlpBlock_0/Dense_0/kernel (768, 3072) float32\n",
      "params/img/Transformer/encoderblock_10/MlpBlock_0/Dense_1/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_10/MlpBlock_0/Dense_1/kernel (3072, 768) float32\n",
      "params/img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/key/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/out/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768) float32\n",
      "params/img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/query/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/value/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_11/LayerNorm_0/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_11/LayerNorm_0/scale (768,) float32\n",
      "params/img/Transformer/encoderblock_11/LayerNorm_1/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_11/LayerNorm_1/scale (768,) float32\n",
      "params/img/Transformer/encoderblock_11/MlpBlock_0/Dense_0/bias (3072,) float32\n",
      "params/img/Transformer/encoderblock_11/MlpBlock_0/Dense_0/kernel (768, 3072) float32\n",
      "params/img/Transformer/encoderblock_11/MlpBlock_0/Dense_1/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_11/MlpBlock_0/Dense_1/kernel (3072, 768) float32\n",
      "params/img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/key/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/out/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768) float32\n",
      "params/img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/query/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/value/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_2/LayerNorm_0/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_2/LayerNorm_0/scale (768,) float32\n",
      "params/img/Transformer/encoderblock_2/LayerNorm_1/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_2/LayerNorm_1/scale (768,) float32\n",
      "params/img/Transformer/encoderblock_2/MlpBlock_0/Dense_0/bias (3072,) float32\n",
      "params/img/Transformer/encoderblock_2/MlpBlock_0/Dense_0/kernel (768, 3072) float32\n",
      "params/img/Transformer/encoderblock_2/MlpBlock_0/Dense_1/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_2/MlpBlock_0/Dense_1/kernel (3072, 768) float32\n",
      "params/img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/key/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/out/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768) float32\n",
      "params/img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/query/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/value/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_3/LayerNorm_0/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_3/LayerNorm_0/scale (768,) float32\n",
      "params/img/Transformer/encoderblock_3/LayerNorm_1/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_3/LayerNorm_1/scale (768,) float32\n",
      "params/img/Transformer/encoderblock_3/MlpBlock_0/Dense_0/bias (3072,) float32\n",
      "params/img/Transformer/encoderblock_3/MlpBlock_0/Dense_0/kernel (768, 3072) float32\n",
      "params/img/Transformer/encoderblock_3/MlpBlock_0/Dense_1/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_3/MlpBlock_0/Dense_1/kernel (3072, 768) float32\n",
      "params/img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/key/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/out/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768) float32\n",
      "params/img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/query/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/value/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_4/LayerNorm_0/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_4/LayerNorm_0/scale (768,) float32\n",
      "params/img/Transformer/encoderblock_4/LayerNorm_1/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_4/LayerNorm_1/scale (768,) float32\n",
      "params/img/Transformer/encoderblock_4/MlpBlock_0/Dense_0/bias (3072,) float32\n",
      "params/img/Transformer/encoderblock_4/MlpBlock_0/Dense_0/kernel (768, 3072) float32\n",
      "params/img/Transformer/encoderblock_4/MlpBlock_0/Dense_1/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_4/MlpBlock_0/Dense_1/kernel (3072, 768) float32\n",
      "params/img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/key/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/out/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768) float32\n",
      "params/img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/query/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/value/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_5/LayerNorm_0/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_5/LayerNorm_0/scale (768,) float32\n",
      "params/img/Transformer/encoderblock_5/LayerNorm_1/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_5/LayerNorm_1/scale (768,) float32\n",
      "params/img/Transformer/encoderblock_5/MlpBlock_0/Dense_0/bias (3072,) float32\n",
      "params/img/Transformer/encoderblock_5/MlpBlock_0/Dense_0/kernel (768, 3072) float32\n",
      "params/img/Transformer/encoderblock_5/MlpBlock_0/Dense_1/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_5/MlpBlock_0/Dense_1/kernel (3072, 768) float32\n",
      "params/img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/key/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/out/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768) float32\n",
      "params/img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/query/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/value/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_6/LayerNorm_0/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_6/LayerNorm_0/scale (768,) float32\n",
      "params/img/Transformer/encoderblock_6/LayerNorm_1/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_6/LayerNorm_1/scale (768,) float32\n",
      "params/img/Transformer/encoderblock_6/MlpBlock_0/Dense_0/bias (3072,) float32\n",
      "params/img/Transformer/encoderblock_6/MlpBlock_0/Dense_0/kernel (768, 3072) float32\n",
      "params/img/Transformer/encoderblock_6/MlpBlock_0/Dense_1/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_6/MlpBlock_0/Dense_1/kernel (3072, 768) float32\n",
      "params/img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/key/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/out/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768) float32\n",
      "params/img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/query/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/value/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_7/LayerNorm_0/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_7/LayerNorm_0/scale (768,) float32\n",
      "params/img/Transformer/encoderblock_7/LayerNorm_1/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_7/LayerNorm_1/scale (768,) float32\n",
      "params/img/Transformer/encoderblock_7/MlpBlock_0/Dense_0/bias (3072,) float32\n",
      "params/img/Transformer/encoderblock_7/MlpBlock_0/Dense_0/kernel (768, 3072) float32\n",
      "params/img/Transformer/encoderblock_7/MlpBlock_0/Dense_1/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_7/MlpBlock_0/Dense_1/kernel (3072, 768) float32\n",
      "params/img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/key/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/out/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768) float32\n",
      "params/img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/query/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/value/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_8/LayerNorm_0/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_8/LayerNorm_0/scale (768,) float32\n",
      "params/img/Transformer/encoderblock_8/LayerNorm_1/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_8/LayerNorm_1/scale (768,) float32\n",
      "params/img/Transformer/encoderblock_8/MlpBlock_0/Dense_0/bias (3072,) float32\n",
      "params/img/Transformer/encoderblock_8/MlpBlock_0/Dense_0/kernel (768, 3072) float32\n",
      "params/img/Transformer/encoderblock_8/MlpBlock_0/Dense_1/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_8/MlpBlock_0/Dense_1/kernel (3072, 768) float32\n",
      "params/img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/key/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/out/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768) float32\n",
      "params/img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/query/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/value/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_9/LayerNorm_0/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_9/LayerNorm_0/scale (768,) float32\n",
      "params/img/Transformer/encoderblock_9/LayerNorm_1/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_9/LayerNorm_1/scale (768,) float32\n",
      "params/img/Transformer/encoderblock_9/MlpBlock_0/Dense_0/bias (3072,) float32\n",
      "params/img/Transformer/encoderblock_9/MlpBlock_0/Dense_0/kernel (768, 3072) float32\n",
      "params/img/Transformer/encoderblock_9/MlpBlock_0/Dense_1/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_9/MlpBlock_0/Dense_1/kernel (3072, 768) float32\n",
      "params/img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/key/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/out/bias (768,) float32\n",
      "params/img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768) float32\n",
      "params/img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/query/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64) float32\n",
      "params/img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/value/bias (12, 64) float32\n",
      "params/img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64) float32\n",
      "params/img/embedding/bias (768,) float32\n",
      "params/img/embedding/kernel (768, 3, 14, 14) float32\n",
      "params/img/pos_embedding (1, 1370, 768) float32\n"
     ]
    }
   ],
   "source": [
    "big_vision_vit = u.npload(local_np_save_path)\n",
    "for key in big_vision_vit.keys():\n",
    "    print(key, big_vision_vit[key].shape, big_vision_vit[key].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
